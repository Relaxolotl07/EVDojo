<!doctype html><html lang="en"><head>  <meta charset="utf-8" />  <meta name="viewport" content="width=device-width, initial-scale=1" />  <title>EVDojo — Interview Analysis</title>  <style>    :root { --bg: #0f1115; --fg: #e6e6e6; --muted:#9aa3ad; --accent:#b76e79; }    * { box-sizing: border-box; }    body { margin: 0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Inter, "Helvetica Neue", Arial; background: var(--bg); color: var(--fg); }    header { padding: 20px; display:flex; gap:14px; align-items:center; justify-content:space-between; border-bottom: 1px solid #1b1f2a; }    h1 { font-size: clamp(18px, 3vw, 26px); margin: 0; letter-spacing: .3px; }    .wrap { display:grid; grid-template-columns: 1fr 340px; gap:20px; padding: 16px; max-width: 1200px; margin: 0 auto; }    @media (max-width: 980px){ .wrap{ grid-template-columns: 1fr; } }    .stage { position: relative; border-radius: 18px; overflow: hidden; background:#0b0d12; border:1px solid #1b1f2a; }    video, canvas { width: 100%; height: auto; display:block; background: #000; }    .hud { position:absolute; inset: 12px; display:flex; justify-content:space-between; align-items:flex-start; pointer-events:none; }    .pill { pointer-events:auto; display:inline-flex; align-items:center; gap:8px; padding:8px 12px; border-radius:999px; background:#121622; border:1px solid #252b3a; color:var(--fg); font-size:12px; }    .controls { display:flex; gap:10px; flex-wrap:wrap; }    button, select { background:#151a26; color: var(--fg); border:1px solid #2a3142; padding:10px 14px; border-radius:12px; font-weight:600; cursor:pointer; }    button:hover { border-color:#3a435a; }    .sidebar { border:1px solid #1b1f2a; border-radius: 18px; padding: 14px; background:#0b0d12; }    .card { border:1px solid #1b1f2a; border-radius: 14px; padding: 12px; margin-top:12px; background:#0e131c; }    .stat { display:flex; justify-content:space-between; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; color: var(--muted); }    .big { font-size: 26px; font-weight: 800; color: var(--fg); }    a { color: var(--accent); text-decoration: none; }    .footer { padding: 10px 16px; text-align:center; color: var(--muted); font-size: 12px; }  </style></head><body>  <header>    <h1>EVDojo — Interview Analysis (Head‑Nod Detector)</h1>    <div class="controls">      <button id="startBtn">▶ Start camera</button>      <button id="stopBtn" disabled>⏹ Stop</button>      <label class="pill"><input id="drawToggle" type="checkbox" checked style="accent-color:#b76e79; margin-right:6px;"> Draw landmarks</label>      <select id="camSelect" title="Camera"></select>    </div>  </header>  <main class="wrap">    <section class="stage">      <video id="video" playsinline muted></video>      <canvas id="overlay"></canvas>      <div class="hud">        <div class="pill" id="statusPill">Model: loading…</div>        <div style="display:flex; gap:8px;">          <div class="pill" id="nodPill">Nods: <span id="nodCount">0</span></div>          <div class="pill" id="smilePill">Smiles: <span id="smileCount">0</span></div>          <div class="pill" id="mouthPill">Mouth: <span id="mouthCount">0</span></div>        </div>      </div>    </section>    <aside class="sidebar">      <h3 style="margin:8px 0 4px">How it works</h3>      <ol style="margin:8px 0 0 18px; color: var(--muted); line-height:1.5">        <li>Loads <b>MediaPipe Face Landmarker</b> (3D landmarks).</li>        <li>Computes head <b>pitch angle</b> from eye–ear geometry.</li>        <li>Tracks a down‑then‑up pattern crossing thresholds to count a <b>nod</b>.</li>      </ol>      <div class="card">        <div class="stat"><span>Pitch (°)</span><span class="big" id="pitchDeg">–</span></div>        <div class="stat"><span>State</span><span id="fsmState">idle</span></div>        <div class="stat"><span>FPS</span><span id="fps">0</span></div>      </div>      <div class="card" style="font-size:13px; color:var(--muted)">        Tip: Sit ~0.5–1.0m from camera, good lighting, face the camera.        <br/>You can tweak thresholds in the <code>CONFIG</code> object in the JS below.      </div>      <div class="card" style="font-size:12px; color:var(--muted)">        <b>Troubleshooting</b>        <ul style="margin:8px 0 0 18px">          <li>This page uses WASM; if your browser blocks it, serve with COOP/COEP headers.</li>          <li>If offline, host the <code>wasm/</code> assets and the .task locally.</li>        </ul>      </div>      <div class="card" style="font-size:12px; color:var(--muted)">        Model: <a href="https://developers.google.com/mediapipe/solutions/vision/face_landmarker" target="_blank" rel="noreferrer">MediaPipe Face Landmarker</a>      </div>    </aside>  </main>  <div class="footer">No video leaves your device. All processing happens in your browser.</div>  <script type="module">    import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.12";    const els = {      start: document.getElementById('startBtn'),      stop: document.getElementById('stopBtn'),      drawToggle: document.getElementById('drawToggle'),      camSelect: document.getElementById('camSelect'),      video: document.getElementById('video'),      canvas: document.getElementById('overlay'),      nodCount: document.getElementById('nodCount'),      pitchDeg: document.getElementById('pitchDeg'),      fps: document.getElementById('fps'),      state: document.getElementById('fsmState'),      statusPill: document.getElementById('statusPill'),    };    const CONFIG = {      SMOOTHING: 0.8,      // Lower nod thresholds so it triggers more easily      DOWN_THRESH: 10,      UP_THRESH: 4,      MAX_NOD_MS: 900,      MIN_GAP_MS: 250,      // Additional gesture thresholds (normalized by face box)      MOUTH_OPEN_THRESH: 0.16,      MOUTH_HYST: 0.04,      SMILE_THRESH: 0.42,      SMILE_HYST: 0.05,      DRAW: true,    };    let faceLandmarker; let stream; let animId; let lastTs = 0, frames = 0;    const FSM = { state: 'idle', tDown: 0, lastNod: 0, count: 0 };    const Smile = { on:false, last:0, count:0 };    const Mouth = { on:false, last:0, count:0 };    const Smooth = { value: 0, init: false, step(x){ if(!this.init){ this.value = x; this.init = true; return x; } this.value = CONFIG.SMOOTHING * this.value + (1 - CONFIG.SMOOTHING) * x; return this.value; }};    function angleABC(A,B,C){ const v1 = {x:A.x-B.x, y:A.y-B.y, z:A.z-B.z}; const v2 = {x:C.x-B.x, y:C.y-B.y, z:C.z-B.z}; const dot = v1.x*v2.x + v1.y*v2.y + v1.z*v2.z; const m1 = Math.hypot(v1.x, v1.y, v1.z); const m2 = Math.hypot(v2.x, v2.y, v2.z); const cos = Math.min(1, Math.max(-1, dot/(m1*m2))); return (Math.acos(cos) * 180/Math.PI); }    function estimatePitchDeg(landmarks){ const L = landmarks[234]; const R = landmarks[454]; const N = landmarks[6]; if(!(L && R && N)) return null; const mid = { x:(L.x+R.x)/2, y:(L.y+R.y)/2, z:(L.z+R.z)/2 }; const vMN = { x:N.x-mid.x, y:N.y-mid.y, z:N.z-mid.z }; const downRef = { x:0, y:1, z:0 }; const deg = angleABC({x:N.x+downRef.x,y:N.y+downRef.y,z:N.z+downRef.z}, N, {x:N.x+vMN.x,y:N.y+vMN.y,z:N.z+vMN.z}); const pitch = 90 - deg; return Math.max(-30, Math.min(30, pitch)); }    function updateFSM(pitch, now){ const t = now; switch(FSM.state){ case 'idle': if(pitch > CONFIG.DOWN_THRESH && (t - FSM.lastNod) > CONFIG.MIN_GAP_MS){ FSM.state = 'down'; FSM.tDown = t; } break; case 'down': if(pitch < CONFIG.UP_THRESH){ if(t - FSM.tDown <= CONFIG.MAX_NOD_MS){ FSM.count++; FSM.lastNod = t; FSM.state = 'idle'; flash(); } else { FSM.state = 'idle'; } } break; } els.state.textContent = FSM.state; els.nodCount.textContent = String(FSM.count); }    function flash(){ const pill = els.nodCount.closest('.pill'); pill.style.background = '#10231b'; pill.style.borderColor = '#1e5b3a'; pill.style.transition = 'all .25s ease'; setTimeout(()=>{ pill.style.background=''; pill.style.borderColor=''; }, 220); }    async function listCameras(){ const devices = await navigator.mediaDevices.enumerateDevices(); const cams = devices.filter(d=>d.kind==='videoinput'); els.camSelect.innerHTML = cams.map((c,i)=>`<option value="${c.deviceId}">${c.label||`Camera ${i+1}`}</option>`).join(''); }    async function startCamera(){ const deviceId = els.camSelect.value || undefined; stream = await navigator.mediaDevices.getUserMedia({ video: { deviceId, width: {ideal: 1280}, height: {ideal: 720} }, audio:false }); els.video.srcObject = stream; await els.video.play(); sizeCanvas(); }    function stopCamera(){ if(stream){ stream.getTracks().forEach(t=>t.stop()); stream = null; } cancelAnimationFrame(animId); animId = null; }    function sizeCanvas(){ const { videoWidth:w, videoHeight:h } = els.video; if(!w || !h) return; els.canvas.width = w; els.canvas.height = h; }    function drawLandmarks(ctx, landmarks){ ctx.save(); ctx.fillStyle = 'rgba(183,110,121,0.9)'; for(const p of landmarks){ ctx.beginPath(); ctx.arc(p.x*els.canvas.width, p.y*els.canvas.height, 2.0, 0, Math.PI*2); ctx.fill(); } ctx.restore(); }    function dist(a,b){ const dx=(a.x-b.x), dy=(a.y-b.y), dz=(a.z-b.z||0); return Math.hypot(dx,dy,dz); }    function bbox(lm){ let minX=1,minY=1,maxX=0,maxY=0; for(const p of lm){ if(!p) continue; if(p.x<minX)minX=p.x; if(p.x>maxX)maxX=p.x; if(p.y<minY)minY=p.y; if(p.y>maxY)maxY=p.y; } return {minX,minY,maxX,maxY}; }    function flashPill(pillId, bg='#10231b', br='#1e5b3a'){ const pill=document.getElementById(pillId); if(!pill) return; const prevBg=pill.style.background, prevBr=pill.style.borderColor; pill.style.background=bg; pill.style.borderColor=br; pill.style.transition='all .25s ease'; setTimeout(()=>{ pill.style.background=prevBg; pill.style.borderColor=prevBr; }, 220); }    function loop(){      animId = requestAnimationFrame(loop);      if(!faceLandmarker || !stream) return;      const now = performance.now();      const results = faceLandmarker.detectForVideo(els.video, now);      const ctx = els.canvas.getContext('2d');      ctx.clearRect(0,0,els.canvas.width,els.canvas.height);      if(results.faceLandmarks && results.faceLandmarks[0]){        const lm = results.faceLandmarks[0];        // Pitch/nod        const rawPitch = estimatePitchDeg(lm);        if(rawPitch !== null){ const pitch = Smooth.step(rawPitch); els.pitchDeg.textContent = pitch.toFixed(1); updateFSM(pitch, now); }        // Smile/Mouth signals        const box = bbox(lm); const faceW = Math.max(1e-6, box.maxX - box.minX); const faceH = Math.max(1e-6, box.maxY - box.minY);        const lipUp = lm[13], lipLow = lm[14], leftC = lm[61], rightC = lm[291];        if(lipUp && lipLow && leftC && rightC){          const mouthOpen = Math.abs(lipLow.y - lipUp.y) / faceH; // normalized 0..~0.5          const smileWidth = dist(leftC, rightC) / faceW;         // normalized 0..~1          // Mouth open FSM with hysteresis          const moOn = mouthOpen > (CONFIG.MOUTH_OPEN_THRESH + (Mouth.on? -CONFIG.MOUTH_HYST : 0));          if(moOn && !Mouth.on && (now - Mouth.last) > CONFIG.MIN_GAP_MS){ Mouth.on = true; Mouth.last = now; Mouth.count++; document.getElementById('mouthCount').textContent = String(Mouth.count); flashPill('mouthPill'); }          if(!moOn && Mouth.on){ Mouth.on = false; }          // Smile FSM with hysteresis          const smOn = smileWidth > (CONFIG.SMILE_THRESH + (Smile.on? -CONFIG.SMILE_HYST : 0));          if(smOn && !Smile.on && (now - Smile.last) > CONFIG.MIN_GAP_MS){ Smile.on = true; Smile.last = now; Smile.count++; document.getElementById('smileCount').textContent = String(Smile.count); flashPill('smilePill', '#22122b', '#5a2a6b'); }          if(!smOn && Smile.on){ Smile.on = false; }        }        if(CONFIG.DRAW && els.drawToggle.checked){ drawLandmarks(ctx, lm); }      } else {        els.state.textContent = 'searching…';      }      frames++; if(now - lastTs >= 1000){ els.fps.textContent = String(frames); frames = 0; lastTs = now; }    }    async function loadModel(){ els.statusPill.textContent = 'Model: loading…'; const WASM_BASE = "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.12/wasm"; const MODEL_URL = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task"; try { const fileset = await FilesetResolver.forVisionTasks(WASM_BASE); faceLandmarker = await FaceLandmarker.createFromOptions(fileset, { baseOptions: { modelAssetPath: MODEL_URL }, runningMode: 'VIDEO', numFaces: 1, outputFaceBlendshapes: false, outputFacialTransformationMatrixes: false }); els.statusPill.textContent = 'Model: ready'; } catch(err){ console.error(err); els.statusPill.textContent = 'Model: failed to load'; throw err; } }    els.start.addEventListener('click', async () => { try{ els.start.disabled = true; els.stop.disabled = false; await listCameras(); await startCamera(); if(!faceLandmarker) await loadModel(); loop(); } catch(err){ console.error(err); const msg = (err && err.message) ? err.message : String(err); alert('Could not start camera or model.\n' + msg + '\nIf this persists, try a local server with COOP/COEP headers.'); els.statusPill.textContent = 'Model: error'; els.start.disabled = false; els.stop.disabled = true; } });    els.stop.addEventListener('click', () => { els.stop.disabled = true; els.start.disabled = false; stopCamera(); });    els.camSelect.addEventListener('change', async () => { if(stream){ stopCamera(); await startCamera(); if(faceLandmarker && !animId) loop(); } });    window.addEventListener('resize', sizeCanvas);    if(!('mediaDevices' in navigator)){ els.statusPill.textContent = 'Error: no mediaDevices support'; }  </script></body></html>